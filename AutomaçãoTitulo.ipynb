{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJg2SckGg5PrabP5y5JQPX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoStrufaldi/Automa-o-GoogleColab/blob/main/Automa%C3%A7%C3%A3oTitulo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xd2XAUpbsLl",
        "outputId": "322d3d54-727f-4104-b2ba-c89193817adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.4.0\n",
            "Arquivo Excel '/Titulo.xlsx' lido com sucesso!\n",
            "Processando linha 100/1179...\n",
            "Processando linha 200/1179...\n",
            "Processando linha 300/1179...\n",
            "Processando linha 400/1179...\n",
            "Processando linha 500/1179...\n",
            "Processando linha 600/1179...\n",
            "Processando linha 700/1179...\n",
            "Processando linha 800/1179...\n",
            "Processando linha 900/1179...\n",
            "Processando linha 1000/1179...\n",
            "Processando linha 1100/1179...\n",
            "\n",
            "Processo finalizado! O arquivo 'titulos_gerados.xlsx' foi gerado com sucesso.\n"
          ]
        }
      ],
      "source": [
        "# Instala as bibliotecas necess√°rias\n",
        "!pip install openpyxl\n",
        "!pip install unidecode\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "\n",
        "def extrair_informacoes(nome, descricao):\n",
        "    \"\"\"\n",
        "    Extrai informa√ß√µes chave do nome e da descri√ß√£o do produto.\n",
        "    \"\"\"\n",
        "    info = {}\n",
        "    nome = str(nome)\n",
        "    descricao = str(descricao)\n",
        "    info['modelo'] = ''\n",
        "\n",
        "    # 1. Extrair Marca\n",
        "    marcas = ['Atlas', 'Electrolux', 'Mueller', 'Esmaltec', 'Realce', 'Clarice', 'Dako']\n",
        "    info['marca'] = ''\n",
        "    for marca in marcas:\n",
        "        if re.search(r'\\b' + marca + r'\\b', nome, re.IGNORECASE):\n",
        "            info['marca'] = marca\n",
        "            break\n",
        "    if not info.get('marca'):\n",
        "        for marca in marcas:\n",
        "            if re.search(r'\\b' + marca + r'\\b', descricao, re.IGNORECASE):\n",
        "                info['marca'] = marca\n",
        "                break\n",
        "\n",
        "    # 2. Extrair Pe√ßas e garantir a ordem\n",
        "    pecas = []\n",
        "    if 'queimador' in nome.lower() or 'queimadores' in nome.lower(): pecas.append('Queimadores')\n",
        "    if 'espalhador' in nome.lower() or 'espalhadores' in nome.lower(): pecas.append('Espalhadores')\n",
        "    if 'grelha' in nome.lower() or 'grelhas' in nome.lower(): pecas.append('Grelhas')\n",
        "    info['pecas'] = sorted(list(set(pecas)), key=['Queimadores', 'Espalhadores', 'Grelhas'].index)\n",
        "\n",
        "    # 3. Extrair N√∫mero de Bocas\n",
        "    bocas_match = re.search(r'(\\d)\\s?(bcs|bc|bocas|b\\b)', nome, re.IGNORECASE)\n",
        "    if bocas_match:\n",
        "        info['bocas'] = f\"{bocas_match.group(1)} Bocas\"\n",
        "\n",
        "    # 4. Extrair Modelo\n",
        "    modelo_str = nome\n",
        "    noise_words = [\n",
        "        'KIT', 'JOGO', 'PE√áAS', 'GRELHA', 'GRELHAS', 'ESMALTADA', 'ESMALTADO',\n",
        "        'ESPALHADOR', 'ESPALHADORES', 'QUEIMADOR', 'QUEIMADORES',\n",
        "        'PARA', 'FOG√ÉO', 'FOG√ïES', 'ORIGINAL'\n",
        "    ]\n",
        "    if info.get('marca'):\n",
        "        modelo_str = re.sub(r'\\b' + info['marca'] + r'\\b', '', modelo_str, flags=re.IGNORECASE)\n",
        "    modelo_str = re.sub(r'\\b(\\d[GTPMC].*?)\\b', '', modelo_str, flags=re.IGNORECASE)\n",
        "    bocas_pattern_match = re.search(r'(\\d+\\s?(?:bcs|bc|bocas|b\\b))', modelo_str, re.IGNORECASE)\n",
        "    if bocas_pattern_match:\n",
        "        modelo_str = modelo_str.replace(bocas_pattern_match.group(1), '')\n",
        "    for word in noise_words:\n",
        "        modelo_str = re.sub(r'\\b' + word + r'\\b', '', modelo_str, flags=re.IGNORECASE)\n",
        "    modelo_str = re.sub(r'[^\\w\\s.]', '', modelo_str)\n",
        "    modelo_limpo = ' '.join(modelo_str.split())\n",
        "    if modelo_limpo:\n",
        "        if info.get('marca') and info['marca'].lower() == 'electrolux':\n",
        "            info['modelo'] = modelo_limpo.upper()\n",
        "        else:\n",
        "            info['modelo'] = modelo_limpo.title()\n",
        "\n",
        "    # 5. Extrair configura√ß√£o das bocas\n",
        "    config = {}\n",
        "    for line in descricao.split('\\n'):\n",
        "        line = line.strip()\n",
        "        match = re.search(r'^(\\d+)\\s*-', line)\n",
        "        if not match: continue\n",
        "        count = match.group(1)\n",
        "        line_upper = line.upper()\n",
        "        if 'TRIPLA CHAMA' in line_upper: config['TC'] = f\"{count}TC\"\n",
        "        elif 'GIGANTE' in line_upper: config['GT'] = f\"{count}GT\"\n",
        "        elif 'GRANDES' in line_upper or 'GRANDE' in line_upper: config['G'] = f\"{count}G\"\n",
        "        elif 'M√âDIOS' in line_upper or 'M√âDIO' in line_upper: config['M'] = f\"{count}M\"\n",
        "        elif 'PEQUENOS' in line_upper or 'PEQUENO' in line_upper: config['P'] = f\"{count}P\"\n",
        "    config_list = []\n",
        "    order = ['TC', 'GT', 'G', 'M', 'P']\n",
        "    for key in order:\n",
        "        if key in config: config_list.append(config[key])\n",
        "    info['config_bocas'] = \" \".join(config_list)\n",
        "\n",
        "    # 6. Extrair lista de compatibilidade\n",
        "    info['compatibilidade'] = ''\n",
        "    compat_match = re.search(r'compat[i√≠]ve(?:l|is)\\s+com(.*?)(?:OBS:|ANTES DA COMPRA|$)', descricao, re.IGNORECASE | re.DOTALL)\n",
        "    if compat_match:\n",
        "        lista_modelos = compat_match.group(1)\n",
        "        lista_modelos = re.sub(r'^\\s*(?:os modelos|os fog√µes \\d bocas)\\s*[:\\-]?\\s*', '', lista_modelos, flags=re.IGNORECASE)\n",
        "        cleaned_models = ' '.join(lista_modelos.split()).strip()\n",
        "        if cleaned_models:\n",
        "            info['compatibilidade'] = cleaned_models\n",
        "\n",
        "    # 7. Keywords Adicionais\n",
        "    info['sabaf'] = 'Sabaf' if 'sabaf' in descricao.lower() else ''\n",
        "    return info\n",
        "\n",
        "def corte_inteligente(texto, limite):\n",
        "    if len(texto) <= limite: return texto\n",
        "    texto_cortado = texto[:limite]\n",
        "    ultimo_espaco = texto_cortado.rfind(' ')\n",
        "    return texto_cortado[:ultimo_espaco] if ultimo_espaco != -1 else texto_cortado\n",
        "\n",
        "def criar_titulo_ml(info):\n",
        "    pecas_plural = info.get('pecas', [])\n",
        "    pecas_plural_str_plus = ' + '.join(pecas_plural) if pecas_plural else \"Pe√ßas\"\n",
        "    pecas_plural_str_noplus = ' '.join(pecas_plural) if pecas_plural else \"Pe√ßas\"\n",
        "    pecas_singular_list = [p[:-2] if p.endswith('es') else (p[:-1] if p.endswith('s') else p) for p in pecas_plural]\n",
        "    pecas_singular_str_noplus = ' '.join(pecas_singular_list) if pecas_singular_list else \"Pe√ßa\"\n",
        "\n",
        "    marca = info.get('marca', '')\n",
        "    modelo = info.get('modelo', '')\n",
        "    bocas = info.get('bocas', '')\n",
        "    config_bocas = info.get('config_bocas', '')\n",
        "    bocas_num = \"\".join(filter(str.isdigit, bocas))\n",
        "    bocas_full = f\"{bocas_num} Bocas\" if bocas_num else \"\"\n",
        "    bocas_abbr = f\"{bocas_num}B\" if bocas_num else \"\"\n",
        "    base_produto = f\"Fog√£o {marca} {modelo}\"\n",
        "\n",
        "    def check(title):\n",
        "        cleaned = ' '.join(title.split())\n",
        "        return cleaned if len(cleaned) <= 59 else None\n",
        "\n",
        "    templates = [\n",
        "        f\"Kit {pecas_plural_str_plus} {base_produto} {bocas_full} {config_bocas}\",\n",
        "        f\"Kit {pecas_plural_str_plus} {base_produto} {bocas_full}\",\n",
        "        f\"{pecas_plural_str_plus} {base_produto} {bocas_full}\",\n",
        "        f\"Kit {pecas_plural_str_plus} {base_produto} {bocas_abbr} {config_bocas}\",\n",
        "        f\"Kit {pecas_plural_str_plus} {base_produto} {bocas_abbr}\",\n",
        "        f\"{pecas_plural_str_plus} {base_produto} {bocas_abbr}\",\n",
        "        f\"Kit {pecas_plural_str_noplus} {base_produto} {bocas_abbr}\",\n",
        "        f\"{pecas_plural_str_noplus} {base_produto} {bocas_abbr}\",\n",
        "        f\"{pecas_singular_str_noplus} {base_produto} {bocas_abbr}\",\n",
        "    ]\n",
        "\n",
        "    for t in templates:\n",
        "        titulo_final = check(t)\n",
        "        if titulo_final:\n",
        "            return titulo_final\n",
        "\n",
        "    fallback_title = f\"{pecas_singular_str_noplus} {base_produto} {bocas_abbr}\"\n",
        "    return corte_inteligente(' '.join(fallback_title.split()), 59)\n",
        "\n",
        "# --- FUN√á√ÉO SHOPEE REFEITA COM NOVA L√ìGICA DE 100 CARACTERES ---\n",
        "def criar_titulo_shopee(info, index):\n",
        "    # 1. Preparar todos os componentes\n",
        "    pecas_str = ' + '.join(info.get('pecas', []))\n",
        "    marca = info.get('marca', '')\n",
        "    modelo = info.get('modelo', '')\n",
        "    bocas = info.get('bocas', '')\n",
        "    config_bocas = info.get('config_bocas', '')\n",
        "    sabaf = info.get('sabaf', '')\n",
        "    compatibilidade_bruta = info.get('compatibilidade', '')\n",
        "\n",
        "    prefixo = f\"Kit {pecas_str}\" if pecas_str else \"Kit Pe√ßas Reposi√ß√£o\"\n",
        "\n",
        "    # Cria as duas vers√µes de t√≠tulo base\n",
        "    bocas_abbr = bocas.replace(\"Bocas\", \"B\")\n",
        "    base_full = f\"{prefixo} Fog√£o {marca} {modelo} {bocas} {sabaf} {config_bocas}\"\n",
        "    base_abbr = f\"{prefixo} Fog√£o {marca} {modelo} {bocas_abbr} {sabaf} {config_bocas}\"\n",
        "\n",
        "    titulo_limpo_full = ' '.join(base_full.split())\n",
        "    titulo_limpo_abbr = ' '.join(base_abbr.split())\n",
        "\n",
        "    # 2. L√≥gica de remo√ß√£o de duplicados da compatibilidade\n",
        "    compatibilidade_limpa = ''\n",
        "    if compatibilidade_bruta:\n",
        "        palavras_para_remover = set()\n",
        "        titulo_normalizado = unidecode(titulo_limpo_full.upper())\n",
        "        for palavra in titulo_normalizado.split('+'):\n",
        "            for sub_palavra in palavra.split():\n",
        "                palavras_para_remover.add(sub_palavra)\n",
        "        if modelo:\n",
        "            palavras_para_remover.add(unidecode(modelo.upper()))\n",
        "\n",
        "        if marca and compatibilidade_bruta.upper().startswith(marca.upper()):\n",
        "            compatibilidade_bruta = re.sub(r'^' + re.escape(marca) + r'\\s*[:\\-]?\\s*', '', compatibilidade_bruta, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        modelos_compat = [m.strip() for m in re.split(r',| - ', compatibilidade_bruta) if m.strip()]\n",
        "\n",
        "        modelos_filtrados = []\n",
        "        numeros_no_titulo = {p for p in palavras_para_remover if p.isdigit()}\n",
        "\n",
        "        for m in modelos_compat:\n",
        "            m_normalizado = unidecode(m.upper())\n",
        "            if m_normalizado in palavras_para_remover:\n",
        "                continue\n",
        "\n",
        "            partes = m.split()\n",
        "            if len(partes) > 1 and partes[0] in numeros_no_titulo:\n",
        "                modelos_filtrados.append(\" \".join(partes[1:]))\n",
        "            else:\n",
        "                modelos_filtrados.append(m)\n",
        "\n",
        "        compatibilidade_limpa = \", \".join(modelos_filtrados)\n",
        "\n",
        "    # 3. Construir e testar os t√≠tulos\n",
        "    def check_shopee(title):\n",
        "        cleaned = ' '.join(title.split())\n",
        "        return cleaned if len(cleaned) <= 100 else None\n",
        "\n",
        "    # Cen√°rio 1: Com compatibilidade\n",
        "    if compatibilidade_limpa:\n",
        "        modelos = [m.strip() for m in compatibilidade_limpa.split(',') if m.strip()]\n",
        "\n",
        "        # Tenta com \"Bocas\" por extenso\n",
        "        for i in range(min(len(modelos), 4), 0, -1):\n",
        "            sufixo = \" e mais\" if len(modelos) > i else \"\"\n",
        "            info_adicional = f\"Compat√≠vel com {', '.join(modelos[:i])}{sufixo}\"\n",
        "            titulo = check_shopee(f\"{titulo_limpo_full} üî• {info_adicional}\")\n",
        "            if titulo: return titulo\n",
        "\n",
        "        # Tenta com \"B\" abreviado\n",
        "        for i in range(min(len(modelos), 4), 0, -1):\n",
        "            sufixo = \" e mais\" if len(modelos) > i else \"\"\n",
        "            info_adicional = f\"Compat√≠vel com {', '.join(modelos[:i])}{sufixo}\"\n",
        "            titulo = check_shopee(f\"{titulo_limpo_abbr} üî• {info_adicional}\")\n",
        "            if titulo: return titulo\n",
        "\n",
        "    # Cen√°rio 2: Com benef√≠cios (ou sem nada se n√£o couber)\n",
        "    beneficio_completo = \"Alta Resist√™ncia e Encaixe perfeito\"\n",
        "    beneficio_curto = \"Alta Resist√™ncia\"\n",
        "\n",
        "    templates_beneficio = [\n",
        "        f\"{titulo_limpo_full} üî• {beneficio_completo}\",\n",
        "        f\"{titulo_limpo_full} üî• {beneficio_curto}\",\n",
        "        f\"{titulo_limpo_abbr} üî• {beneficio_completo}\",\n",
        "        f\"{titulo_limpo_abbr} üî• {beneficio_curto}\",\n",
        "        f\"{titulo_limpo_full} üî•\",\n",
        "        f\"{titulo_limpo_abbr} üî•\"\n",
        "    ]\n",
        "\n",
        "    for t in templates_beneficio:\n",
        "        titulo = check_shopee(t)\n",
        "        if titulo: return titulo\n",
        "\n",
        "    # Fallback final, caso o t√≠tulo base seja muito grande\n",
        "    return corte_inteligente(titulo_limpo_abbr, 100)\n",
        "\n",
        "# --- BLOCO PRINCIPAL ---\n",
        "nome_arquivo_entrada = '/Titulo.xlsx'\n",
        "nome_arquivo_saida = 'titulos_gerados.xlsx'\n",
        "try:\n",
        "    if '.xlsx' in nome_arquivo_entrada.lower():\n",
        "        df = pd.read_excel(nome_arquivo_entrada)\n",
        "        print(f\"Arquivo Excel '{nome_arquivo_entrada}' lido com sucesso!\")\n",
        "    else:\n",
        "        df = pd.read_csv(nome_arquivo_entrada)\n",
        "        print(f\"Arquivo CSV '{nome_arquivo_entrada}' lido com sucesso!\")\n",
        "\n",
        "    titulos_ml = []\n",
        "    titulos_shopee = []\n",
        "    for index, row in df.iterrows():\n",
        "        informacoes = extrair_informacoes(row['Nome do Produto'], row['Descri√ß√£o do Produto'])\n",
        "        titulos_ml.append(criar_titulo_ml(informacoes))\n",
        "        titulos_shopee.append(criar_titulo_shopee(informacoes, index))\n",
        "        if (index + 1) % 100 == 0:\n",
        "            print(f\"Processando linha {index+1}/{len(df)}...\")\n",
        "    df_saida = pd.DataFrame({\n",
        "        'Titulo Mercado Livre (60 caracteres)': titulos_ml,\n",
        "        'Titulo Shopee (120 caracteres)': titulos_shopee\n",
        "    })\n",
        "    df_saida.to_excel(nome_arquivo_saida, index=False)\n",
        "    print(f\"\\nProcesso finalizado! O arquivo '{nome_arquivo_saida}' foi gerado com sucesso.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERRO: Arquivo '{nome_arquivo_entrada}' n√£o encontrado.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao processar o arquivo: {e}\")"
      ]
    }
  ]
}